所谓语义检索（也称基于向量的检索），是指检索系统不再拘泥于用户 Query 字面本身，而是能精准捕捉到用户 Query 后面的真正意图并以此来搜索，从而更准确地向用户返回最符合的结果。通过使用最先进的语义索引模型找到文本的向量表示，在高维向量空间中对它们进行索引，并度量查询向量与索引文档的相似程度，从而解决了关键词索引带来的缺陷。

通常检索业务的数据都比较庞大，都会分为**召回**（索引）、**排序**两个环节。召回阶段主要是从至少千万级别的候选集合里面，筛选出相关的文档，这样候选集合的数目就会大大降低，在之后的排序阶段就可以使用一些复杂的模型做精细化或者个性化的排序。一般采用**多路召回策略**（例如**关键词召回**、**热点召回**、**语义召回**结合等），多路召回结果聚合后，经过统一的打分以后选出最优的 **TopK** 的结果。

## 召回模块设计

### Domain-adaptive Pretraining
使用大规模业务数据，对预训练模型（基座模型）进行领域微调。

以文献检索系统为例，采用query、title、keywords、abstract 四个字段内容，构建无标签数据集进行 Domain-adaptive Pretraining。

```
query1\t用户点击的title1\t关键词1\t摘要1
...
```

### SimCES
适用于只有无监督数据的，可使用SimCES进行无监督训练。

采用query、title、keywords 三个字段内容，构造无标签数据集，进行无监督召回训练SimCSE。

```
query1\t用户点击的title1\t关键词1
...
```

### In-batch Negatives
适用于有监督训练。

使用 query、title、keywords，构造带正标签的数据集，不包含负标签样本，基于 In-batch Negatives 策略进行训练

## 排序模块设计
召回模型负责从海量（千万级）候选文本中快速（毫秒级）筛选出与 Query 相关性较高的 TopK Doc，排序模型会在召回模型筛选出的 TopK Doc 结果基础之上针对每一个 (Query, Doc) Pair 对进行两两匹配计算相关性，排序效果更精准。

一般思路是西安基于Point-wise的Cross Encoder构建一个基础模型，再使用Pair-wise方法进行优化

### 基于预训练模型Pair-Wise算法
基本思路是对样本构建偏序文档对，两两比较，从比较中学习顺序，是Point-wise的改进版，但对噪声数据更为敏感。

使用点击（作为正样本）和展现未点击（作为负样本）数据构造排序阶段的训练集，进行精排训练。

```
query1\t用户点击的title1\t用户未点击的title2
```

### Point-Wise算法
只考虑当前Query和每个文档的绝对相关度，并没有考虑其他文档与Query的相关度，但是建模方式比较简单。

## 名词解释
- BERR的输入可以是一个句子对（句子A和句子B），也可使单个句子，一些特殊标志位：
   - [CLS] 放在第一个句子的首位，经过BERT得到的表征向量可以用于后续的人物
   - [SEP] 用于分开两个输入句子
   - [UNK] 未知字符
   - [MASK] 遮盖句子中的一些单词，将单词用[MASK]遮盖之后，再利用输出向量预测单词
- 单塔模型：整个过程中只进行一次模型计算，这里的「塔」指的是进行「几次模型计算」，而不一定是「模型个数」。
- 双塔模型：将输入，而是单独喂给模型，并分别得到各自的embedding向量，再进行后续的计算。
- ANN / KNN：向量检索 

## 参考
- [手把手搭建一个语义检索系统](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/neural_search)
- [Text Matching中的单塔方法和双塔方法](https://zhuanlan.zhihu.com/p/585533302)
- [一文纵览KNN（ANN）向量检索](https://zhuanlan.zhihu.com/p/264367144)
